```markdown
# Лабораторная работа №4 — Введение в нейросети (PyTorch)

## Цель
Познакомиться с базовым пайплайном машинного обучения и нейросетей:
подготовка данных, обучение моделей, сравнение качества классической ML-модели и нейросетей.

---

## Данные
- Файл: `data/exams.csv`
- Объём: 1000 объектов
- Признаки: пол, этническая группа, образование родителей, тип ланча, подготовительный курс, баллы по экзаменам
- Целевая переменная: последний столбец датасета (экзаменационный балл, регрессия)

---

## Предобработка

1. Загрузка данных через `pandas`.
2. Удаление строк с пропусками.
3. Разделение на признаки и целевую переменную.
4. One-Hot-кодирование категориальных признаков (`pd.get_dummies`).
5. Разбиение на train/test: 80% / 20% (`train_test_split`).
6. Масштабирование признаков с помощью `StandardScaler`.

---

## Бейзлайн-модель (классическая ML)

- Модель: `LinearRegression` (sklearn)
- Обучение на нормализованных признаках.
- Метрики на test:
  - RMSE ≈ 3.46  
  - MAE ≈ 2.80  
  - R² ≈ 0.95  

Бейзлайн показывает очень хорошее качество и служит точкой сравнения для нейросетей.

---

## Подготовка данных для PyTorch

- Перевод `X_train`, `X_test`, `y_train`, `y_test` в тензоры `torch.tensor`.
- Создание `TensorDataset` и `DataLoader` для train и test.
- Определение устройства вычислений: `cpu` / `cuda`.

---

## Модель 1 — Простая полносвязная нейросеть

**Архитектура:**

- `Linear(input_dim → 64)` → `ReLU` → `Linear(64 → 1)`

**Обучение:**

- Loss: `MSELoss`
- Оптимизатор: `Adam(lr=1e-3)`
- Эпох: 30
- Сохранение `train_loss` и `val_loss` по эпохам
- Построена кривая обучения (learning curve) через `matplotlib`

**Результат (test):**

- RMSE ≈ 10.8  
- MAE ≈ 8.1  
- R² ≈ 0.62  

Модель явно уступает линейной регрессии и выглядит недообученной.

---

## Модель 2 — Глубокая нейросеть с регуляризацией

**Архитектура (DeepNet):**

- `Linear(input_dim → 128)` → `BatchNorm1d` → `ReLU` → `Dropout(0.3)`  
- `Linear(128 → 128)` → `BatchNorm1d` → `ReLU` → `Dropout(0.3)`  
- `Linear(128 → 1)`

**Обучение:**

- Loss: `MSELoss`
- Оптимизатор: `Adam(lr=1e-3)`
- Эпох: 30
- Сбор `train_loss` и `val_loss` по эпохам
- Построена кривая обучения (learning curve) для глубокой сети

**Результат (test):**

- RMSE ≈ 5.5  
- MAE ≈ 4.4  
- R² ≈ 0.88  

Глубокая сеть работает лучше простой, но всё ещё хуже линейной регрессии.

---

## Выводы

1. Лучшее качество показала **линейная регрессия** — на тесте у неё минимальные ошибки и максимальный R².
2. У нейросетей сильного переобучения не наблюдается: train/test loss убывают примерно параллельно, разрыв небольшой.
3. Есть признаки **недообучения**, особенно у простой сети: её метрики заметно хуже бейзлайна, кривые потерь продолжают падать к последним эпохам.
4. Метрики нейросетей можно улучшить за счёт:
   - увеличения числа эпох обучения;
   - подбора learning rate и размера батча;
   - изменения архитектуры (число слоёв и нейронов);
   - настройки регуляризации (Dropout);
   - экспериментов с признаками.
5. Для данной задачи зависимость близка к линейной, поэтому простая модель линейной регрессии оказывается оптимальным выбором по качеству.
```
